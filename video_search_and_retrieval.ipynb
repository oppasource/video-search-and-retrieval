{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f8b556",
   "metadata": {},
   "source": [
    "# Video search and retrieval\n",
    "\n",
    "In this project we will see how we can retrieve videos based on given user query. And not just the video, but the timestamp of the video that caters to the query asked by the user.\n",
    "\n",
    "The system we will build works purely on text, once we get the transcriptions of the videos that we want to search for. We will use embedding based search. This kind of search has many advantages over the traditional search that it works on semantic level. For this reason, we might get most representative search results even if the words enterd in the query is not present anywhere in the search database/video transcripts.\n",
    "\n",
    "We demonstrate the video search application using a sample of 4 videos downloaded from youtube and placed in the data folder. These 4 videos belong to different categories like: story, data science, programing and chemical engineering. __Whisper__ is used to get transcripts of these videos along with timestamps. We then use __Sentence Transformer__ to get vectors of these small chunks of time stamped transcripts. The vectors are then stored in a vector database for fast search and retrieval of similar vector. We are using __Qdrant__ for vector db management. When user gives a query, it is coverted to vector using same Sentence Tranformer and the vector db is quired. We get the ranked list of the chunks of transcripts which can be processed to present the final search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdaa26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tqdm\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import whisper\n",
    "from qdrant_client import models, QdrantClient\n",
    "\n",
    "encoder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36deb98d",
   "metadata": {},
   "source": [
    "### Fetching video files to perform search on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584c50c",
   "metadata": {},
   "source": [
    "We fetch the list of mp4 files present with the data folder so that we can index them and make search possible on them. All of the videos that we want to index and make search possible for them can be placed within data folder for this project.\n",
    "\n",
    "We see there are 4 mp4 files present in the directory from the output. Their paths are printed as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4552de0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/kids story.mp4', './data/data science.mp4', './data/chem engg.mp4', './data/programing.mp4']\n"
     ]
    }
   ],
   "source": [
    "data_directory = './data'\n",
    "mp4_files = [join(data_directory, f) for f in listdir(data_directory) \n",
    "             if isfile(join(data_directory, f)) and f.endswith('.mp4')]\n",
    "\n",
    "print(mp4_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08847ca",
   "metadata": {},
   "source": [
    "### Transcribing mp4 to text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2415019",
   "metadata": {},
   "source": [
    "We get the transcription of the videos using _whisper_. Note that _tiny_ model is used here and a better model can also be used. Also the _device_ used is _cpu_ but a GPU can also be used for fast transription, specially helpful in longer videos.\n",
    "\n",
    "We save the transcription in python list which contains objects correcponding to each inidividual video in our data. Each object is defined to have _id_ to identify the object, _text_ contianing complete transcription of the video, and segments which contain the utterances and its corresponding information. We will index these segments rather than the text directly so we can retrieve the exact location where the answer is possible within the video and not just the video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3f9373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:42<00:00, 10.56s/it]\n"
     ]
    }
   ],
   "source": [
    "transcriptions = []\n",
    "\n",
    "speech2text_model = whisper.load_model(\"tiny\", device='cpu')\n",
    "\n",
    "for mp4_file in tqdm.tqdm(mp4_files):\n",
    "    result = speech2text_model.transcribe(mp4_file)\n",
    "    transcriptions.append({'id': mp4_file, 'text': result['text'], 'segments' : result['segments']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f50166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(transcriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d07310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/chem engg.mp4\n"
     ]
    }
   ],
   "source": [
    "print(transcriptions[2]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428f8ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What in the world do chemical engineers do? Make life saving medicines, accessible to everyone. Develop and deliver new energy sources safely and responsibly. Eliminate plastic waste from our oceans. When it comes to getting things done, chemical engineers have a pretty full to do list. We do the math, science and engineering to make medicine accessible. Water, drinkable, air, breathable. The deep thinking to make the environment sustainable, systems affordable, safety, reliable. We make discoveries scalable and the inconceivable, feasible. So what in the world do chemical engineers do? We take things that have never been done and get them done. For good. AICHE doing a world of good.\n"
     ]
    }
   ],
   "source": [
    "print(transcriptions[2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29caeda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'seek': 0, 'start': 0.0, 'end': 4.0, 'text': ' What in the world do chemical engineers do?', 'tokens': [50364, 708, 294, 264, 1002, 360, 7313, 11955, 360, 30, 50564], 'temperature': 0.0, 'avg_logprob': -0.30902165174484253, 'compression_ratio': 1.3445945945945945, 'no_speech_prob': 0.1661727875471115}\n"
     ]
    }
   ],
   "source": [
    "print(transcriptions[2]['segments'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b4b70",
   "metadata": {},
   "source": [
    "### Setting up the vector db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb4aaa",
   "metadata": {},
   "source": [
    "We now set up a vector database using Qdrant. We create a collection names _videos_ where we will be indexing all the vectors corresponding to the utterances. We define the dimension of vector same as that of sentence transformer vector dimension since those are the vectors we will be storing in the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da754d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de7e774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create collection to store data\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=\"videos\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672b6b1",
   "metadata": {},
   "source": [
    "In the below cell, we add each indivdual utterances from transcription segments to the vector db. We append the transcription id and segment id to form a unique id for the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59d805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 66.44it/s]\n",
      "32it [00:00, 52.28it/s]\n",
      "13it [00:00, 55.45it/s]\n",
      "25it [00:00, 53.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for transcription_idx, transcription in enumerate(transcriptions, 1):\n",
    "    for segment_idx, segment in tqdm.tqdm(enumerate(transcription['segments'], 1)):\n",
    "        payload_doc = {\"transcription\": transcription, \"segment\": segment}\n",
    "        \n",
    "        qdrant.upload_records(\n",
    "            collection_name=\"videos\",\n",
    "            records=[models.Record(id=int(str(transcription_idx) + str(segment_idx)), \n",
    "                                   vector=encoder.encode(segment[\"text\"]).tolist(), \n",
    "                                   payload=payload_doc)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41bef6",
   "metadata": {},
   "source": [
    "We can now query our vector database with a query that we have to retrieve information from any of the indexed dialogues/utterances from the videos. The query is first converted into vector using the same sentence transformer that was used to index videos. This is necessary since we want to have same encoding model to compute similarities between vectors.\n",
    "\n",
    "We list down the id of the video, the utterance or dialogue, seek to locate where to start the video from and score which indicates how similar the query and the retrieved utterance is.\n",
    "\n",
    "Here we use an example query as \"_chem enginers work_\" to get results. The top most result that we get is from the the chem engg video itself which starts as \"_What in the world do chemical engineers do?_\". We purposely made spelling errors in the query to demonstrate the effectiveness of vector db. None of the words present in the query are present in the retrieved dialogue. It was still abel to retrieve it. \n",
    "\n",
    "We can process this ranked list further to generate the final output results that we want to give our users. It can be just the top 3 unique videos rather than time stamp, or processing based on score that we get, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d8957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video id: ./data/chem engg.mp4\n",
      " Dialogue: What in the world do chemical engineers do?\n",
      " Seek: 0\n",
      " score: 0.5513292127919139\n",
      "-----------\n",
      "Video id: ./data/chem engg.mp4\n",
      " Dialogue: So what in the world do chemical engineers do?\n",
      " Seek: 5200\n",
      " score: 0.5466465182951933\n",
      "-----------\n",
      "Video id: ./data/chem engg.mp4\n",
      " Dialogue: When it comes to getting things done, chemical engineers have a pretty full to do list.\n",
      " Seek: 2500\n",
      " score: 0.5319760024110961\n",
      "-----------\n",
      "Video id: ./data/data science.mp4\n",
      " Dialogue: Their job is to use techniques like machine learning, predictive modeling, data mining,\n",
      " Seek: 2864\n",
      " score: 0.2413862063049848\n",
      "-----------\n",
      "Video id: ./data/chem engg.mp4\n",
      " Dialogue: Develop and deliver new energy sources safely and responsibly.\n",
      " Seek: 0\n",
      " score: 0.23827743765568876\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "query = \"chem enginers work\"\n",
    "\n",
    "hits = qdrant.search(\n",
    "    collection_name=\"videos\",\n",
    "    query_vector=encoder.encode(query).tolist(),\n",
    "    limit=5\n",
    ")\n",
    "for hit in hits:\n",
    "    print('Video id: ' + str(hit.payload['transcription']['id']) + '\\n', \n",
    "          'Dialogue: ' + str(hit.payload['segment']['text'].strip()) + '\\n', \n",
    "          'Seek: ' + str(hit.payload['segment']['seek']) + '\\n',\n",
    "          \"score:\", hit.score)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6d0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
